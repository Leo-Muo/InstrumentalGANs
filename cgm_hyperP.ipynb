{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Dropout, LSTM, Bidirectional\n",
    "from tensorflow.keras.layers import BatchNormalization, LeakyReLU\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from music21 import converter, instrument, note, chord, stream\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SEQUENCE_LENGTH = 100\n",
    "LATENT_DIMENSION = 1000\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 100\n",
    "SAMPLE_INTERVAL = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_notes():\n",
    "    \"\"\" Get all the notes and chords from the midi files \"\"\"\n",
    "    notes = []\n",
    "\n",
    "    for file in Path(\"midi\").glob(\"*.mid\"):\n",
    "        midi = converter.parse(file)\n",
    "\n",
    "        print(\"Parsing %s\" % file)\n",
    "\n",
    "        notes_to_parse = midi.flat.notes\n",
    "\n",
    "        for element in notes_to_parse:\n",
    "            if isinstance(element, note.Note):\n",
    "                notes.append(str(element.pitch))\n",
    "            elif isinstance(element, chord.Chord):\n",
    "                notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "\n",
    "    return notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_sequences(notes, n_vocab):\n",
    "    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n",
    "    sequence_length = 100\n",
    "\n",
    "    # Get all pitch names\n",
    "    pitchnames = sorted(set(item for item in notes))\n",
    "\n",
    "    # Create a dictionary to map pitches to integers\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "\n",
    "    network_input = []\n",
    "    network_output = []\n",
    "\n",
    "    # create input sequences and the corresponding outputs\n",
    "    for i in range(0, len(notes) - sequence_length, 1):\n",
    "        sequence_in = notes[i:i + sequence_length]\n",
    "        sequence_out = notes[i + sequence_length]\n",
    "        network_input.append([note_to_int[char] for char in sequence_in])\n",
    "        network_output.append(note_to_int[sequence_out])\n",
    "\n",
    "    n_patterns = len(network_input)\n",
    "\n",
    "    # Reshape the input into a format compatible with LSTM layers\n",
    "    network_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "    \n",
    "    # Normalize input between -1 and 1\n",
    "    network_input = (network_input - float(n_vocab) / 2) / (float(n_vocab) / 2)\n",
    "    network_output = to_categorical(network_output, num_classes=n_vocab)  # Use to_categorical from TensorFlow's Keras\n",
    "\n",
    "    return network_input, network_output  # Add this return statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_midi(prediction_output, filename):\n",
    "    \"\"\" convert the output from the prediction to notes and create a midi file\n",
    "        from the notes \"\"\"\n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "\n",
    "    # create note and chord objects based on the values generated by the model\n",
    "    for item in prediction_output:\n",
    "        pattern = item[0]\n",
    "        # pattern is a chord\n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                new_note = note.Note(int(current_note))\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "        # pattern is a note\n",
    "        else:\n",
    "            new_note = note.Note(pattern)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            output_notes.append(new_note)\n",
    "\n",
    "        # increase offset each iteration so that notes do not stack\n",
    "        offset += 0.5\n",
    "\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "    midi_stream.write('midi', fp='{}.mid'.format(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "class GAN():\n",
    "    def __init__(self, rows, latent_dim, d_lr, d_beta_1, g_lr, g_beta_1):\n",
    "        self.seq_length = rows\n",
    "        self.seq_shape = (self.seq_length, 1)\n",
    "        self.latent_dim = latent_dim\n",
    "        self.disc_loss = []\n",
    "        self.gen_loss = []\n",
    "\n",
    "        d_optimizer = Adam(d_lr, d_beta_1)\n",
    "        g_optimizer = Adam(g_lr, g_beta_1)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy', optimizer=d_optimizer, metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # The generator takes noise as input and generates note sequences\n",
    "        z = Input(shape=(self.latent_dim,))\n",
    "        generated_seq = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The discriminator takes generated images as input and determines validity\n",
    "        validity = self.discriminator(generated_seq)\n",
    "\n",
    "        # The combined model (stacked generator and discriminator)\n",
    "        # Trains the generator to fool the discriminator\n",
    "        self.combined = Model(z, validity)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=g_optimizer)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(512, input_shape=self.seq_shape, return_sequences=True))\n",
    "        model.add(Bidirectional(LSTM(512)))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(256))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(100))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.summary()\n",
    "\n",
    "        seq = Input(shape=self.seq_shape)\n",
    "        validity = model(seq)\n",
    "\n",
    "        return Model(seq, validity)\n",
    "\n",
    "    def build_generator(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(256, input_dim=self.latent_dim))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(1024))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(np.prod(self.seq_shape), activation='tanh'))\n",
    "        model.add(Reshape(self.seq_shape))\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        seq = model(noise)\n",
    "\n",
    "        return Model(noise, seq)\n",
    "\n",
    "    def train(self, epochs, batch_size=128, sample_interval=50):\n",
    "\n",
    "        # Load and convert the data\n",
    "        notes = get_notes()\n",
    "        n_vocab = len(set(notes))\n",
    "        X_train, y_train = prepare_sequences(notes, n_vocab)\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        real = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "\n",
    "        # Training the model\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # Training the discriminator\n",
    "            # Select a random batch of note sequences\n",
    "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            real_seqs = X_train[idx]\n",
    "\n",
    "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "\n",
    "            # Generate a batch of new note sequences\n",
    "            gen_seqs = self.generator.predict(noise)\n",
    "\n",
    "            # Train the discriminator\n",
    "            d_loss_real = self.discriminator.train_on_batch(real_seqs, real)\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_seqs, fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            # Training the Generator\n",
    "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "\n",
    "            # Train the generator (to have the discriminator label samples as real)\n",
    "            g_loss = self.combined.train_on_batch(noise, real)\n",
    "            \n",
    "            # Ensure g_loss is a float\n",
    "            if isinstance(g_loss, list):\n",
    "                g_loss = g_loss[0]\n",
    "\n",
    "            # Print the progress and save into loss lists\n",
    "            if epoch % sample_interval == 0:\n",
    "                print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100 * d_loss[1], g_loss))\n",
    "                self.disc_loss.append(d_loss[0])\n",
    "                self.gen_loss.append(g_loss)\n",
    "\n",
    "        self.generate(notes)\n",
    "        self.plot_loss()\n",
    "\n",
    "    def generate(self, input_notes):\n",
    "        notes = input_notes\n",
    "        pitchnames = sorted(set(item for item in notes))\n",
    "        int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
    "\n",
    "        noise = np.random.normal(0, 1, (1, self.latent_dim))\n",
    "        predictions = self.generator.predict(noise)\n",
    "\n",
    "        pred_notes = [x * 242 + 242 for x in predictions[0]]\n",
    "\n",
    "        pred_notes_mapped = []\n",
    "        for x in pred_notes:\n",
    "            index = int(x)\n",
    "            if index in int_to_note:\n",
    "                pred_notes_mapped.append(int_to_note[index])\n",
    "            else:\n",
    "                pred_notes_mapped.append('C5')\n",
    "\n",
    "        create_midi(pred_notes_mapped, 'gan_final')\n",
    "\n",
    "    def plot_loss(self):\n",
    "        plt.plot(self.disc_loss, c='red')\n",
    "        plt.plot(self.gen_loss, c='blue')\n",
    "        plt.title(\"GAN Loss per Epoch\")\n",
    "        plt.legend(['Discriminator', 'Generator'])\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.savefig('GAN_Loss_per_Epoch_final.png', transparent=True)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    rows = 100  # Example fixed value for rows\n",
    "    latent_dim = trial.suggest_int('latent_dim', 100, 1000)\n",
    "    d_lr = trial.suggest_loguniform('d_lr', 1e-5, 1e-3)\n",
    "    d_beta_1 = trial.suggest_uniform('d_beta_1', 0.1, 0.9)\n",
    "    g_lr = trial.suggest_loguniform('g_lr', 1e-5, 1e-3)\n",
    "    g_beta_1 = trial.suggest_uniform('g_beta_1', 0.1, 0.9)\n",
    "\n",
    "    gan = GAN(rows, latent_dim, d_lr, d_beta_1, g_lr, g_beta_1)\n",
    "    gan.train(epochs=10, batch_size=128, sample_interval=50)\n",
    "\n",
    "    # Return the average loss of the last few epochs\n",
    "    avg_disc_loss = np.mean(gan.disc_loss[-5:])\n",
    "    return avg_disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "print('Best hyperparameters:', study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'latent_dim': 486, 'd_lr': 2.5932849036781864e-05, 'd_beta_1': 0.46723024851957, 'g_lr': 3.2136735964331895e-05, 'g_beta_1': 0.39037140058318687}\n"
     ]
    }
   ],
   "source": [
    "print('Best hyperparameters:', study.best_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
